{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ghZse9Yq3dz_",
    "outputId": "4bbe03a8-a94a-441d-c352-c375bf470760"
   },
   "outputs": [],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v0oE_fIX335s"
   },
   "source": [
    "# Install Yolov8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "57R1h6PR37in",
    "outputId": "1f227e34-a75b-4a8d-c9fd-caba60fda7b2"
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "from IPython.display import display,Image\n",
    "from IPython import display\n",
    "display.clear_output()\n",
    "!yolo mode=checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wTyRW1qu7YCl"
   },
   "source": [
    "# Train the Yolov8 model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RgDrWqXZ7kUI"
   },
   "source": [
    "### Download the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gSpHI7oZ5FnU"
   },
   "outputs": [],
   "source": [
    "!pip install roboflow\n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"put your API KEY\")\n",
    "project = rf.workspace(\"deep-learing-p9dxb\").project(\"detection-drowsiness\")\n",
    "dataset = project.version(1).download(\"yolov8\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZUt7cxSz3MNs"
   },
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wKjGz75Z3MNt"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# data-gradients (suitable for performing EDA on complex image dataset)\n",
    "!pip install data-gradients\n",
    "\n",
    "# for displaying pdfs as images\n",
    "!pip install pdf2image\n",
    "!apt-get install poppler-utils\n",
    "\n",
    "# for pretty printing json\n",
    "!pip install Pygments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lZOZpgTp-u9l"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from pdf2image import convert_from_path\n",
    "from IPython.display import display\n",
    "\n",
    "def display_pdf_pages (pdf_path):\n",
    "    \"\"\"\n",
    "    Display each page of a PDF file as images in separate output cells.\n",
    "    Args:\n",
    "    pdf_path (str): The path to the PDF file.\n",
    "    Raises:\n",
    "    FileNotFoundError: If the specified PDF file is not found.\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Convert PDF to a list of PIL Images\n",
    "        images = convert_from_path(pdf_path)\n",
    "\n",
    "        # Display each image\n",
    "        for i, image in enumerate(images):\n",
    "          # Display the image\n",
    "          display(image)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(\"The specified PDF file was not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2-R0fDNb_z_G"
   },
   "source": [
    "The print_pretty_json function opens a JSON file, formats the data with an indent of 4 spaces using json.dumps, applies syntax highlighting with Pygments, and prints the pretty-printed JSON data in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3XWZoK73_6lk"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pygments import highlight, lexers, formatters\n",
    "from pathlib import Path\n",
    "\n",
    "def print_pretty_json(file_path):\n",
    "    \"\"\"\n",
    "    Function to pretty print a JSON file with colorization.\n",
    "    Args:\n",
    "    file_path (Union[str, Path]): The path of the JSON file to be pretty-printed.\n",
    "    Raises:\n",
    "    FileNotFoundError: If the file at 'file_path doesn't exist.\n",
    "    json.JSONDecodeError: If the file at 'file_path is not valid JSON.\n",
    "    \"\"\"\n",
    "    try:\n",
    "      # Open the file\n",
    "      with open(file_path, 'r') as f:\n",
    "        # Load the JSON data from the file\n",
    "        data= json.load(f)\n",
    "    except FileNotFoundError:\n",
    "      raise FileNotFoundError (f\"File not found: {file_path}\")\n",
    "    except json.JSONDecodeError:\n",
    "      raise json.JSONDecodeError(\"Invalid JSON file\", \"\", 0)\n",
    "\n",
    "    # Pretty print the JSON data with an indent of 4 spaces\n",
    "    formatted_json = json.dumps (data, indent=4)\n",
    "\n",
    "    # Colorize the pretty-printed JSON data\n",
    "    colorful_json = highlight(formatted_json,\n",
    "                              lexers.JsonLexer(),\n",
    "                              formatters.TerminalFormatter()\n",
    "                              )\n",
    "    # Print the colorized, pretty-printed JSON data\n",
    "    print(colorful_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qcb3l5ZB6YGp"
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "# define path to YAML file\n",
    "yaml_file_path = '/content/detection-drowsiness--1/data.yaml'\n",
    "\n",
    "# open the YAML file and load it into a dictionary\n",
    "with open(yaml_file_path, 'r') as f:\n",
    "  data_yaml = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bdu54sEg8aRd"
   },
   "outputs": [],
   "source": [
    "# Instantiating Dataloaders\n",
    "dataset_params = {\n",
    "    'data_dir':'/content/detection-drowsiness--1',\n",
    "    'train_images_dir':'train/images',\n",
    "    'train_labels_dir':'train/labels',\n",
    "    'val_images_dir':'valid/images',\n",
    "    'val_labels_dir':'valid/labels',\n",
    "    'test_images_dir':'test/images',\n",
    "    'test_labels_dir':'test/labels',\n",
    "    'classes': ['awake', 'drowsy']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9RUmwxHQCVCN"
   },
   "outputs": [],
   "source": [
    "from data_gradients.datasets.detection import YoloFormatDetectionDataset\n",
    "train_set = YoloFormatDetectionDataset (root_dir=\"/content/detection-drowsiness--1\",\n",
    "                                        images_dir=\"train/images\",\n",
    "                                        labels_dir=\"train/labels\")\n",
    "\n",
    "val_set = YoloFormatDetectionDataset (root_dir=\"/content/detection-drowsiness--1\",\n",
    "                                      images_dir=\"valid/images\",\n",
    "                                      labels_dir=\"valid/labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YOVgK3D7GIBl",
    "outputId": "167276c4-8e0b-46a7-f37f-51090a3512a2"
   },
   "outputs": [],
   "source": [
    "from data_gradients.managers.detection_manager import DetectionAnalysisManager\n",
    "import matplotlib\n",
    "matplotlib.use('Agg') # This line is only for Colab\n",
    "\n",
    "analyzer = DetectionAnalysisManager(\n",
    "    report_title=\"Testing Data-Gradients Object Detection\",\n",
    "    train_data=train_set,\n",
    "    val_data=val_set,\n",
    "    class_names=['awake', 'drowsy'],\n",
    ")\n",
    "\n",
    "analyzer.run()\n",
    "# when running, input 0, then 0, then 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "gPJOrnbmI40H",
    "outputId": "109e6333-6af7-48f8-8047-4575b5c12fd7"
   },
   "outputs": [],
   "source": [
    "display_pdf_pages(\"/content/logs/Testing_Data-Gradients_Object_Detection/Report.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lxPKhnHsKJmT"
   },
   "outputs": [],
   "source": [
    "# Acessing report in json format\n",
    "# report_json = '/content/logs/Testing_Data-Gradients_Object_Detection/summary.json'\n",
    "# print_pretty_json(report_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q0RQ6cKQLNpm"
   },
   "outputs": [],
   "source": [
    "def run_detection_analysis(report_title,\n",
    "                           feature_extractors,\n",
    "                           train_data,\n",
    "                           val_data,\n",
    "                           class_names):\n",
    "\n",
    "    # create an instance of DetectionAnalysisManager\n",
    "    analyzer = DetectionAnalysisManager(\n",
    "      report_title=report_title,\n",
    "      feature_extractors = feature_extractors,\n",
    "      train_data=train_data,\n",
    "      val_data=val_data,\n",
    "      class_names = class_names\n",
    "    )\n",
    "\n",
    "    # Run the analysis\n",
    "    analyzer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7ehiqQD7MWlx",
    "outputId": "b66d36f6-df34-406c-b099-036a4d9e4fcb"
   },
   "outputs": [],
   "source": [
    "run_detection_analysis(report_title= 'DetectionBoundingBoxPerImageCount',\n",
    "                        feature_extractors = 'DetectionBoundingBoxPerImageCount',\n",
    "                        train_data=train_set,\n",
    "                        val_data=val_set,\n",
    "                        class_names=['awake', 'drowsy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "moU9mO75NpKy",
    "outputId": "0d5a581d-5d32-40f8-e591-82af0d08a346"
   },
   "outputs": [],
   "source": [
    "display_pdf_pages('/content/logs/DetectionBoundingBoxPerImageCount/Report.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jcnIY0kpN-eB",
    "outputId": "c4aba7f7-482f-499e-8876-a3ad41b45379"
   },
   "outputs": [],
   "source": [
    "report_json = '/content/logs/DetectionBoundingBoxPerImageCount/summary.json'\n",
    "print_pretty_json(report_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D4yq8-vBCYgA"
   },
   "source": [
    "# The model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S9qiEB3E7XF4",
    "outputId": "3159e95a-187d-409e-dd0c-7ca5bf5f492f"
   },
   "outputs": [],
   "source": [
    "!yolo task=detect mode=train model=yolov8s.pt data={dataset.location}/data.yaml epochs =15 imgsz = 640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 321
    },
    "id": "AyoD2pJZDVvf",
    "outputId": "c02e8258-6e43-4ee7-f5e3-833707fce3c1"
   },
   "outputs": [],
   "source": [
    "Image(filename =f'/content/runs/detect/train/confusion_matrix.png', width = 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 321
    },
    "id": "06US9iBJDyZ8",
    "outputId": "30d3f717-5c4b-46d4-ca6a-26518070cee1"
   },
   "outputs": [],
   "source": [
    "Image(filename= f'/content/runs/detect/train/results.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8MILxDh0Fmoi",
    "outputId": "47d1370e-edc9-4bd3-955c-bd53fd981808"
   },
   "outputs": [],
   "source": [
    "!yolo task= detect mode=val model= /content/runs/detect/train/weights/best.pt data={dataset.location}/data.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gkl9lEm3DJzr"
   },
   "source": [
    "# The results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y5Q2YxRzDNpR",
    "outputId": "f7b29d43-c3d8-4206-bb4f-4ad84ec4c444"
   },
   "outputs": [],
   "source": [
    "!yolo task= detect mode=val model= /content/runs/detect/train/weights/best.pt data={dataset.location}/test.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PPstkKkoDOWs"
   },
   "source": [
    "# show the test sample results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hEQS5dYyGHDJ",
    "outputId": "838c19ef-b850-4924-9a16-b2f14efa8fb3"
   },
   "outputs": [],
   "source": [
    "!yolo task=detect mode= predict model= /content/runs/detect/train/weights/best.pt conf=0.5 source ={dataset.location}/test/images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "rkDM7AvlGklq",
    "outputId": "6b3e48e3-ad54-445f-e91c-945ae1f3a6c4"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "from IPython.display import Image, display\n",
    "for image_path in glob.glob(f'/content/runs/detect/predict/*.jpg'):\n",
    "  display(Image(filename= image_path ,height = 600))\n",
    "  print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "id": "Jq7pj6BoKYp1",
    "outputId": "f99a1b02-bcb6-4c37-a15a-f1c316738b83"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "from time import time\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "import supervision as sv\n",
    "\n",
    "\n",
    "class ObjectDetection:\n",
    "\n",
    "    def __init__(self, capture_index):\n",
    "\n",
    "        self.capture_index = capture_index\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        print(\"Using Device: \", self.device)\n",
    "        self.model = self.load_model()\n",
    "        self.CLASS_NAMES_DICT = self.model.model.names\n",
    "        self.box_annotator = sv.BoxAnnotator(sv.ColorPalette.default(), thickness=3, text_thickness=3, text_scale=1.5)\n",
    "\n",
    "    def load_model(self):\n",
    "\n",
    "        model = YOLO(\"best.pt\")  # load a pretrained YOLOv8n model\n",
    "        model.fuse()\n",
    "\n",
    "        return model\n",
    "\n",
    "    def predict(self, frame):\n",
    "\n",
    "        results = self.model(frame)\n",
    "\n",
    "        return results\n",
    "\n",
    "    def plot_bboxes(self, results, frame):\n",
    "\n",
    "        xyxys = []\n",
    "        confidences = []\n",
    "        class_ids = []\n",
    "\n",
    "        # Extract detections for person class\n",
    "        for result in results:\n",
    "            boxes = result.boxes.cpu().numpy()\n",
    "            if len(boxes) > 0:\n",
    "                class_id = boxes.cls[0]\n",
    "                conf = boxes.conf[0]\n",
    "                xyxy = boxes.xyxy[0]\n",
    "\n",
    "                if class_id == 0.0:\n",
    "                    xyxys.append(result.boxes.xyxy.cpu().numpy())\n",
    "                    confidences.append(result.boxes.conf.cpu().numpy())\n",
    "                    class_ids.append(result.boxes.cls.cpu().numpy().astype(int))\n",
    "\n",
    "        # Setup detections for visualization\n",
    "        detections = sv.Detections(\n",
    "            xyxy=results[0].boxes.xyxy.cpu().numpy(),\n",
    "            confidence=results[0].boxes.conf.cpu().numpy(),\n",
    "            class_id=results[0].boxes.cls.cpu().numpy().astype(int),\n",
    "        )\n",
    "\n",
    "        # Assuming detections.xyxy, detections.confidence, detections.class_id, and detections.tracker_id are numpy arrays/lists or None\n",
    "        xyxy = detections.xyxy if detections.xyxy is not None else []\n",
    "        confidence = detections.confidence if detections.confidence is not None else []\n",
    "        class_id = detections.class_id if detections.class_id is not None else []\n",
    "        tracker_id = detections.tracker_id if detections.tracker_id is not None else []\n",
    "\n",
    "        self.labels = [f\"{self.CLASS_NAMES_DICT[class_id]} {conf.item():0.2f}\"\n",
    "                       for xy, conf, class_id, tracker_id in zip(xyxy, confidence, class_id, tracker_id)]\n",
    "\n",
    "        # Annotate and display frame\n",
    "        frame = self.box_annotator.annotate(scene=frame, detections=detections, labels=self.labels)\n",
    "\n",
    "        return frame\n",
    "\n",
    "    def __call__(self):\n",
    "        cap = cv2.VideoCapture(self.capture_index)\n",
    "        assert cap.isOpened()\n",
    "        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "\n",
    "        while True:\n",
    "            start_time = time()\n",
    "\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:  # Check if the frame was read successfully\n",
    "                break  # Break the loop if there are no more frames\n",
    "\n",
    "            results = self.predict(frame)\n",
    "            frame = self.plot_bboxes(results, frame)\n",
    "\n",
    "            end_time = time()\n",
    "            fps = 1 / np.round(end_time - start_time, 2)\n",
    "\n",
    "            plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "            plt.title(f'YOLOv8 Detection - FPS: {int(fps)}')\n",
    "            plt.axis('off')\n",
    "            plt.pause(0.001)\n",
    "\n",
    "        cap.release()\n",
    "        plt.close()\n",
    "\n",
    "# Create an instance of ObjectDetection\n",
    "detector = ObjectDetection(capture_index=1)\n",
    "\n",
    "# print(cv2.VideoCapture(0).isOpened())\n",
    "# Run the object detection loop\n",
    "detector()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
